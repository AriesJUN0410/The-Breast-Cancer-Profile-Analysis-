{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f7ca465",
   "metadata": {
    "papermill": {
     "duration": 0.004605,
     "end_time": "2023-02-13T17:58:22.979518",
     "exception": false,
     "start_time": "2023-02-13T17:58:22.974913",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Save RSNA dataset as 1024x1024 PNGs.\n",
    "\n",
    "This notebook is adapted (with minor modifications) from:  \n",
    "\n",
    "https://www.kaggle.com/code/christofhenkel/se-resnext50-full-gpu-decoding\n",
    "\n",
    "The notebook uses DALI for fast processing of dicom images, and should run in around 6 hours. The resulting dataset is stored in:  \n",
    "\n",
    "https://www.kaggle.com/datasets/lucasrr/rsna-1024x1024-pngs-small\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a101fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-05T06:44:19.900699Z",
     "iopub.status.busy": "2023-02-05T06:44:19.900319Z",
     "iopub.status.idle": "2023-02-05T06:44:19.920765Z",
     "shell.execute_reply": "2023-02-05T06:44:19.919665Z",
     "shell.execute_reply.started": "2023-02-05T06:44:19.900617Z"
    },
    "papermill": {
     "duration": 0.003369,
     "end_time": "2023-02-13T17:58:22.986615",
     "exception": false,
     "start_time": "2023-02-13T17:58:22.983246",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Introduction\n",
    "\n",
    "This kernels uses the recent pip wheel of DALI for decoding dicoms using GPU. It works for all JPEG2000 and most of the JPEG-lossless formated images.\n",
    "\n",
    "The decoding work strongly is based on the kernels of Theo Viel (@theoviel) and David Austin (@tivfrvqhs5)\n",
    "\n",
    "***WARNING***: Allthough the GPU decoding works for all train images, a few of the JPEG-lossless formated DICOMS (TransferSyntaxUID == '1.2.840.10008.1.2.4.70') of the hidden test set cannot be decoded. So its crucial to have a CPU fallback in place so the notebook wont throw an exception in the submission re-run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6229fc9c",
   "metadata": {
    "papermill": {
     "duration": 0.003297,
     "end_time": "2023-02-13T17:58:22.993388",
     "exception": false,
     "start_time": "2023-02-13T17:58:22.990091",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce35519",
   "metadata": {
    "papermill": {
     "duration": 0.003241,
     "end_time": "2023-02-13T17:58:23.000049",
     "exception": false,
     "start_time": "2023-02-13T17:58:22.996808",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We start with installing pip requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "995a4d67",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-02-13T17:58:23.009023Z",
     "iopub.status.busy": "2023-02-13T17:58:23.008290Z",
     "iopub.status.idle": "2023-02-13T17:59:24.468819Z",
     "shell.execute_reply": "2023-02-13T17:59:24.467506Z"
    },
    "papermill": {
     "duration": 61.470952,
     "end_time": "2023-02-13T17:59:24.474447",
     "exception": false,
     "start_time": "2023-02-13T17:58:23.003495",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q timm==0.6.5 --no-index --find-links=/kaggle/input/rsna-bc-pip-requirements\n",
    "!pip install -q albumentations==1.2.1 --no-index --find-links=/kaggle/input/rsna-bc-pip-requirements\n",
    "!pip install -q pylibjpeg-libjpeg==1.3.1 --no-index --find-links=/kaggle/input/rsna-bc-pip-requirements\n",
    "!pip install -q pydicom==2.0.0 --no-index --find-links=/kaggle/input/rsna-bc-pip-requirements\n",
    "!pip install -q python-gdcm==3.0.20 --no-index --find-links=/kaggle/input/rsna-bc-pip-requirements\n",
    "!pip install -q dicomsdl==0.109.1 --no-index --find-links=/kaggle/input/rsna-bc-pip-requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83349bc",
   "metadata": {
    "papermill": {
     "duration": 0.013859,
     "end_time": "2023-02-13T17:59:24.499310",
     "exception": false,
     "start_time": "2023-02-13T17:59:24.485451",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Then we install the latest DALI packaging which we will use for GPU decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae8f760f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-13T17:59:24.508968Z",
     "iopub.status.busy": "2023-02-13T17:59:24.508611Z",
     "iopub.status.idle": "2023-02-13T18:00:06.102901Z",
     "shell.execute_reply": "2023-02-13T18:00:06.101754Z"
    },
    "papermill": {
     "duration": 41.602214,
     "end_time": "2023-02-13T18:00:06.105597",
     "exception": false,
     "start_time": "2023-02-13T17:59:24.503383",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q /kaggle/input/nvidia-dali-nightly-cuda110-1230dev/nvidia_dali_nightly_cuda110-1.23.0.dev20230203-7187866-py3-none-manylinux2014_x86_64.whl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5557be7",
   "metadata": {
    "papermill": {
     "duration": 0.004018,
     "end_time": "2023-02-13T18:00:06.114020",
     "exception": false,
     "start_time": "2023-02-13T18:00:06.110002",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Next, we import all the packages we need and patch a function to allow for INT16 support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3612a02a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-13T18:00:06.124814Z",
     "iopub.status.busy": "2023-02-13T18:00:06.123269Z",
     "iopub.status.idle": "2023-02-13T18:00:11.079650Z",
     "shell.execute_reply": "2023-02-13T18:00:11.078632Z"
    },
    "papermill": {
     "duration": 4.964263,
     "end_time": "2023-02-13T18:00:11.082331",
     "exception": false,
     "start_time": "2023-02-13T18:00:06.118068",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import timm\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import os, sys\n",
    "from copy import copy\n",
    "import gc\n",
    "import shutil \n",
    "import time\n",
    "\n",
    "import glob\n",
    "from scipy.special import expit\n",
    "\n",
    "import albumentations as A\n",
    "import cv2\n",
    "cv2.setNumThreads(0)\n",
    "\n",
    "import dicomsdl\n",
    "import pydicom\n",
    "from pydicom.filebase import DicomBytesIO\n",
    "\n",
    "from os.path import join\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing as mp\n",
    "\n",
    "from types import SimpleNamespace\n",
    "from typing import Any, Dict\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "\n",
    "import nvidia.dali.fn as fn\n",
    "import nvidia.dali.types as types\n",
    "from nvidia.dali import pipeline_def\n",
    "from nvidia.dali.types import DALIDataType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b59716c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-13T18:00:11.092905Z",
     "iopub.status.busy": "2023-02-13T18:00:11.092543Z",
     "iopub.status.idle": "2023-02-13T18:00:11.105538Z",
     "shell.execute_reply": "2023-02-13T18:00:11.104721Z"
    },
    "papermill": {
     "duration": 0.020967,
     "end_time": "2023-02-13T18:00:11.107789",
     "exception": false,
     "start_time": "2023-02-13T18:00:11.086822",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#we need to patch DALI for Int16 support\n",
    "\n",
    "from nvidia.dali.backend import TensorGPU, TensorListGPU\n",
    "from nvidia.dali.pipeline import Pipeline\n",
    "import nvidia.dali.ops as ops\n",
    "from nvidia.dali import types\n",
    "from nvidia.dali.plugin.base_iterator import _DaliBaseIterator\n",
    "from nvidia.dali.plugin.base_iterator import LastBatchPolicy\n",
    "import torch\n",
    "import torch.utils.dlpack as torch_dlpack\n",
    "import ctypes\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import pydicom\n",
    "\n",
    "to_torch_type = {\n",
    "    types.DALIDataType.FLOAT:   torch.float32,\n",
    "    types.DALIDataType.FLOAT64: torch.float64,\n",
    "    types.DALIDataType.FLOAT16: torch.float16,\n",
    "    types.DALIDataType.UINT8:   torch.uint8,\n",
    "    types.DALIDataType.INT8:    torch.int8,\n",
    "    types.DALIDataType.UINT16:  torch.int16,\n",
    "    types.DALIDataType.INT16:   torch.int16,\n",
    "    types.DALIDataType.INT32:   torch.int32,\n",
    "    types.DALIDataType.INT64:   torch.int64\n",
    "}\n",
    "\n",
    "\n",
    "def feed_ndarray(dali_tensor, arr, cuda_stream=None):\n",
    "    \"\"\"\n",
    "    Copy contents of DALI tensor to PyTorch's Tensor.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    `dali_tensor` : nvidia.dali.backend.TensorCPU or nvidia.dali.backend.TensorGPU\n",
    "                    Tensor from which to copy\n",
    "    `arr` : torch.Tensor\n",
    "            Destination of the copy\n",
    "    `cuda_stream` : torch.cuda.Stream, cudaStream_t or any value that can be cast to cudaStream_t.\n",
    "                    CUDA stream to be used for the copy\n",
    "                    (if not provided, an internal user stream will be selected)\n",
    "                    In most cases, using pytorch's current stream is expected (for example,\n",
    "                    if we are copying to a tensor allocated with torch.zeros(...))\n",
    "    \"\"\"\n",
    "    dali_type = to_torch_type[dali_tensor.dtype]\n",
    "\n",
    "    assert dali_type == arr.dtype, (\"The element type of DALI Tensor/TensorList\"\n",
    "                                    \" doesn't match the element type of the target PyTorch Tensor: \"\n",
    "                                    \"{} vs {}\".format(dali_type, arr.dtype))\n",
    "    assert dali_tensor.shape() == list(arr.size()), \\\n",
    "        (\"Shapes do not match: DALI tensor has size {0}, but PyTorch Tensor has size {1}\".\n",
    "            format(dali_tensor.shape(), list(arr.size())))\n",
    "    cuda_stream = types._raw_cuda_stream(cuda_stream)\n",
    "\n",
    "    # turn raw int to a c void pointer\n",
    "    c_type_pointer = ctypes.c_void_p(arr.data_ptr())\n",
    "    if isinstance(dali_tensor, (TensorGPU, TensorListGPU)):\n",
    "        stream = None if cuda_stream is None else ctypes.c_void_p(cuda_stream)\n",
    "        dali_tensor.copy_to_external(c_type_pointer, stream, non_blocking=True)\n",
    "    else:\n",
    "        dali_tensor.copy_to_external(c_type_pointer)\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f47d01d",
   "metadata": {
    "papermill": {
     "duration": 0.003925,
     "end_time": "2023-02-13T18:00:11.115849",
     "exception": false,
     "start_time": "2023-02-13T18:00:11.111924",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Next I set major variables which handle the public run and the re-run on the hidden test set, and also allow for simulating the size of the hidden test set by setting RAM_CHECK = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b87e36fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-13T18:00:11.126320Z",
     "iopub.status.busy": "2023-02-13T18:00:11.126029Z",
     "iopub.status.idle": "2023-02-13T18:00:11.380169Z",
     "shell.execute_reply": "2023-02-13T18:00:11.379207Z"
    },
    "papermill": {
     "duration": 0.262389,
     "end_time": "2023-02-13T18:00:11.382348",
     "exception": false,
     "start_time": "2023-02-13T18:00:11.119959",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len df : 54706\n",
      "Unique patients: 11913\n"
     ]
    }
   ],
   "source": [
    "# Params\n",
    "\n",
    "COMP_FOLDER = '/kaggle/input/rsna-breast-cancer-detection/'\n",
    "DATA_FOLDER = COMP_FOLDER + 'train_images/'\n",
    "\n",
    "N_CORES = mp.cpu_count()\n",
    "MIXED_PRECISION = False\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "train_df = pd.read_csv('/kaggle/input/rsna-breast-cancer-detection/train.csv')\n",
    "\n",
    "# file names:\n",
    "train_df[\"fns\"] = train_df['patient_id'].astype(str) + '/' + train_df['image_id'].astype(str) + '.dcm'\n",
    "\n",
    "print(f'Len df : {len(train_df)}')\n",
    "print(f'Unique patients: {train_df[\"patient_id\"].nunique()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8c0d84",
   "metadata": {
    "papermill": {
     "duration": 0.004235,
     "end_time": "2023-02-13T18:00:11.391071",
     "exception": false,
     "start_time": "2023-02-13T18:00:11.386836",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Next, we define the function for GPU-based decoding using DALI and processing the dicom images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de21247e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-13T18:00:11.401478Z",
     "iopub.status.busy": "2023-02-13T18:00:11.400637Z",
     "iopub.status.idle": "2023-02-13T18:00:11.415031Z",
     "shell.execute_reply": "2023-02-13T18:00:11.414072Z"
    },
    "papermill": {
     "duration": 0.021762,
     "end_time": "2023-02-13T18:00:11.417098",
     "exception": false,
     "start_time": "2023-02-13T18:00:11.395336",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convert_dicom_to_jpg(file, save_folder=\"\"):\n",
    "    patient = file.split('/')[-2]\n",
    "    image = file.split('/')[-1][:-4]\n",
    "    dcmfile = pydicom.dcmread(file)\n",
    "\n",
    "    if dcmfile.file_meta.TransferSyntaxUID == '1.2.840.10008.1.2.4.90':\n",
    "        with open(file, 'rb') as fp:\n",
    "            raw = DicomBytesIO(fp.read())\n",
    "            ds = pydicom.dcmread(raw)\n",
    "        offset = ds.PixelData.find(b\"\\x00\\x00\\x00\\x0C\")  #<---- the jpeg2000 header info we're looking for\n",
    "        hackedbitstream = bytearray()\n",
    "        hackedbitstream.extend(ds.PixelData[offset:])\n",
    "        with open(save_folder + f\"{patient}_{image}.jpg\", \"wb\") as binary_file:\n",
    "            binary_file.write(hackedbitstream)\n",
    "            \n",
    "    if dcmfile.file_meta.TransferSyntaxUID == '1.2.840.10008.1.2.4.70':\n",
    "        with open(file, 'rb') as fp:\n",
    "            raw = DicomBytesIO(fp.read())\n",
    "            ds = pydicom.dcmread(raw)\n",
    "        offset = ds.PixelData.find(b\"\\xff\\xd8\\xff\\xe0\")  #<---- the jpeg lossless header info we're looking for\n",
    "        hackedbitstream = bytearray()\n",
    "        hackedbitstream.extend(ds.PixelData[offset:])\n",
    "        with open(save_folder + f\"{patient}_{image}.jpg\", \"wb\") as binary_file:\n",
    "            binary_file.write(hackedbitstream)\n",
    "\n",
    "            \n",
    "@pipeline_def\n",
    "def jpg_decode_pipeline(jpgfiles):\n",
    "    jpegs, _ = fn.readers.file(files=jpgfiles)  # nvidia.dali.fn\n",
    "    images = fn.experimental.decoders.image(jpegs, device='mixed', output_type=types.ANY_DATA, dtype=DALIDataType.UINT16)\n",
    "    return images\n",
    "\n",
    "def parse_window_element(elem):\n",
    "    if type(elem)==list:\n",
    "        return float(elem[0])\n",
    "    if type(elem)==str:\n",
    "        return float(elem)\n",
    "    if type(elem)==float:\n",
    "        return elem\n",
    "    if type(elem)==pydicom.dataelem.DataElement:\n",
    "        try:\n",
    "            return float(elem[0])\n",
    "        except:\n",
    "            return float(elem.value)\n",
    "    return None\n",
    "\n",
    "def linear_window(data, center, width):\n",
    "    lower, upper = center - width // 2, center + width // 2\n",
    "    data = torch.clamp(data, min=lower, max=upper)\n",
    "    return data \n",
    "\n",
    "def process_dicom(img, dicom):\n",
    "    try:\n",
    "        invert = getattr(dicom, \"PhotometricInterpretation\", None) == \"MONOCHROME1\"\n",
    "    except:\n",
    "        invert = False\n",
    "        \n",
    "    center = parse_window_element(dicom[\"WindowCenter\"]) \n",
    "    width = parse_window_element(dicom[\"WindowWidth\"])\n",
    "        \n",
    "    if (center is not None) & (width is not None):\n",
    "        img = linear_window(img, center, width)\n",
    "\n",
    "    img = (img - img.min()) / (img.max() - img.min())\n",
    "    if invert:\n",
    "        img = 1 - img\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "759e57d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-13T18:00:11.426923Z",
     "iopub.status.busy": "2023-02-13T18:00:11.426621Z",
     "iopub.status.idle": "2023-02-13T18:00:11.432917Z",
     "shell.execute_reply": "2023-02-13T18:00:11.432070Z"
    },
    "papermill": {
     "duration": 0.013368,
     "end_time": "2023-02-13T18:00:11.434759",
     "exception": false,
     "start_time": "2023-02-13T18:00:11.421391",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cfg = SimpleNamespace(**{})\n",
    "cfg.img_size = 1024\n",
    "# cfg.backbone = 'seresnext50_32x4d'\n",
    "# cfg.pretrained=False\n",
    "# cfg.in_channels = 1\n",
    "cfg.classes = ['cancer']\n",
    "cfg.batch_size = 8\n",
    "cfg.data_folder = \"/tmp/output/\"\n",
    "cfg.val_aug = A.CenterCrop(always_apply=False, p=1.0, height=cfg.img_size, width=cfg.img_size)\n",
    "cfg.device = DEVICE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d0b39d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-05T07:14:35.534267Z",
     "iopub.status.busy": "2023-02-05T07:14:35.533224Z",
     "iopub.status.idle": "2023-02-05T07:14:35.545681Z",
     "shell.execute_reply": "2023-02-05T07:14:35.544691Z",
     "shell.execute_reply.started": "2023-02-05T07:14:35.534231Z"
    },
    "papermill": {
     "duration": 0.004093,
     "end_time": "2023-02-13T18:00:11.443335",
     "exception": false,
     "start_time": "2023-02-13T18:00:11.439242",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We will process the dicoms in chunks so the disk space does not become an issue. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "120eb017",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-13T18:00:11.453712Z",
     "iopub.status.busy": "2023-02-13T18:00:11.452947Z",
     "iopub.status.idle": "2023-02-13T18:00:11.459944Z",
     "shell.execute_reply": "2023-02-13T18:00:11.459104Z"
    },
    "papermill": {
     "duration": 0.014057,
     "end_time": "2023-02-13T18:00:11.461935",
     "exception": false,
     "start_time": "2023-02-13T18:00:11.447878",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "SAVE_SIZE = int(cfg.img_size * 1.125)\n",
    "SAVE_FOLDER = cfg.data_folder\n",
    "os.makedirs(SAVE_FOLDER, exist_ok=True)\n",
    "N_CHUNKS = len(train_df[\"fns\"]) // 2000 if len(train_df[\"fns\"]) > 2000 else 1\n",
    "CHUNKS = [(len(train_df[\"fns\"]) / N_CHUNKS * k, len(train_df[\"fns\"]) / N_CHUNKS * (k + 1)) for k in range(N_CHUNKS)]\n",
    "CHUNKS = np.array(CHUNKS).astype(int)\n",
    "JPG_FOLDER = \"/tmp/jpg/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d1c7dac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-13T18:00:11.471744Z",
     "iopub.status.busy": "2023-02-13T18:00:11.471461Z",
     "iopub.status.idle": "2023-02-13T18:00:11.476122Z",
     "shell.execute_reply": "2023-02-13T18:00:11.475105Z"
    },
    "papermill": {
     "duration": 0.013566,
     "end_time": "2023-02-13T18:00:11.479828",
     "exception": false,
     "start_time": "2023-02-13T18:00:11.466262",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n"
     ]
    }
   ],
   "source": [
    "print(N_CHUNKS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2579f040",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-13T18:00:11.490645Z",
     "iopub.status.busy": "2023-02-13T18:00:11.490391Z",
     "iopub.status.idle": "2023-02-13T18:00:12.430979Z",
     "shell.execute_reply": "2023-02-13T18:00:12.429724Z"
    },
    "papermill": {
     "duration": 0.94828,
     "end_time": "2023-02-13T18:00:12.433508",
     "exception": false,
     "start_time": "2023-02-13T18:00:11.485228",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "SAVE_FOLDER = '/kaggle/working/pngs/'\n",
    "!mkdir {SAVE_FOLDER}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9eaf050",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-13T18:00:12.444456Z",
     "iopub.status.busy": "2023-02-13T18:00:12.444145Z",
     "iopub.status.idle": "2023-02-13T21:29:45.811611Z",
     "shell.execute_reply": "2023-02-13T21:29:45.809513Z"
    },
    "papermill": {
     "duration": 12573.376804,
     "end_time": "2023-02-13T21:29:45.815052",
     "exception": false,
     "start_time": "2023-02-13T18:00:12.438248",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk 1 of 27 chunks\n",
      "Converting dicom to jpg...\n",
      "jpg files saved to /tmp/jpg/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2026/2026 [06:01<00:00,  5.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pngs saved to /kaggle/working/pngs/\n",
      "Elapsed time: 476.92s\n",
      "chunk 2 of 27 chunks\n",
      "Converting dicom to jpg...\n",
      "jpg files saved to /tmp/jpg/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2026/2026 [05:47<00:00,  5.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pngs saved to /kaggle/working/pngs/\n",
      "Elapsed time: 945.90s\n",
      "chunk 3 of 27 chunks\n",
      "Converting dicom to jpg...\n",
      "jpg files saved to /tmp/jpg/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2026/2026 [05:33<00:00,  6.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pngs saved to /kaggle/working/pngs/\n",
      "Elapsed time: 1394.89s\n",
      "chunk 4 of 27 chunks\n",
      "Converting dicom to jpg...\n",
      "jpg files saved to /tmp/jpg/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2026/2026 [05:38<00:00,  5.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pngs saved to /kaggle/working/pngs/\n",
      "Elapsed time: 1852.67s\n",
      "chunk 5 of 27 chunks\n",
      "Converting dicom to jpg...\n",
      "jpg files saved to /tmp/jpg/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2026/2026 [05:40<00:00,  5.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pngs saved to /kaggle/working/pngs/\n",
      "Elapsed time: 2313.83s\n",
      "chunk 6 of 27 chunks\n",
      "Converting dicom to jpg...\n",
      "jpg files saved to /tmp/jpg/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2026/2026 [05:43<00:00,  5.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pngs saved to /kaggle/working/pngs/\n",
      "Elapsed time: 2781.42s\n",
      "chunk 7 of 27 chunks\n",
      "Converting dicom to jpg...\n",
      "jpg files saved to /tmp/jpg/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2027/2027 [05:36<00:00,  6.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pngs saved to /kaggle/working/pngs/\n",
      "Elapsed time: 3233.08s\n",
      "chunk 8 of 27 chunks\n",
      "Converting dicom to jpg...\n",
      "jpg files saved to /tmp/jpg/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2026/2026 [05:42<00:00,  5.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pngs saved to /kaggle/working/pngs/\n",
      "Elapsed time: 3696.84s\n",
      "chunk 9 of 27 chunks\n",
      "Converting dicom to jpg...\n",
      "jpg files saved to /tmp/jpg/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2026/2026 [05:51<00:00,  5.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pngs saved to /kaggle/working/pngs/\n",
      "Elapsed time: 4175.55s\n",
      "chunk 10 of 27 chunks\n",
      "Converting dicom to jpg...\n",
      "jpg files saved to /tmp/jpg/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2026/2026 [05:31<00:00,  6.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pngs saved to /kaggle/working/pngs/\n",
      "Elapsed time: 4631.96s\n",
      "chunk 11 of 27 chunks\n",
      "Converting dicom to jpg...\n",
      "jpg files saved to /tmp/jpg/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2026/2026 [05:42<00:00,  5.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pngs saved to /kaggle/working/pngs/\n",
      "Elapsed time: 5091.04s\n",
      "chunk 12 of 27 chunks\n",
      "Converting dicom to jpg...\n",
      "jpg files saved to /tmp/jpg/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2026/2026 [05:36<00:00,  6.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pngs saved to /kaggle/working/pngs/\n",
      "Elapsed time: 5545.99s\n",
      "chunk 13 of 27 chunks\n",
      "Converting dicom to jpg...\n",
      "jpg files saved to /tmp/jpg/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2026/2026 [05:44<00:00,  5.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pngs saved to /kaggle/working/pngs/\n",
      "Elapsed time: 6005.27s\n",
      "chunk 14 of 27 chunks\n",
      "Converting dicom to jpg...\n",
      "jpg files saved to /tmp/jpg/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2027/2027 [05:54<00:00,  5.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pngs saved to /kaggle/working/pngs/\n",
      "Elapsed time: 6488.57s\n",
      "chunk 15 of 27 chunks\n",
      "Converting dicom to jpg...\n",
      "jpg files saved to /tmp/jpg/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2026/2026 [05:53<00:00,  5.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pngs saved to /kaggle/working/pngs/\n",
      "Elapsed time: 6960.08s\n",
      "chunk 16 of 27 chunks\n",
      "Converting dicom to jpg...\n",
      "jpg files saved to /tmp/jpg/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2026/2026 [05:57<00:00,  5.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pngs saved to /kaggle/working/pngs/\n",
      "Elapsed time: 7443.71s\n",
      "chunk 17 of 27 chunks\n",
      "Converting dicom to jpg...\n",
      "jpg files saved to /tmp/jpg/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2026/2026 [05:49<00:00,  5.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pngs saved to /kaggle/working/pngs/\n",
      "Elapsed time: 7916.06s\n",
      "chunk 18 of 27 chunks\n",
      "Converting dicom to jpg...\n",
      "jpg files saved to /tmp/jpg/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2026/2026 [05:34<00:00,  6.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pngs saved to /kaggle/working/pngs/\n",
      "Elapsed time: 8365.84s\n",
      "chunk 19 of 27 chunks\n",
      "Converting dicom to jpg...\n",
      "jpg files saved to /tmp/jpg/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2026/2026 [05:34<00:00,  6.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pngs saved to /kaggle/working/pngs/\n",
      "Elapsed time: 8819.79s\n",
      "chunk 20 of 27 chunks\n",
      "Converting dicom to jpg...\n",
      "jpg files saved to /tmp/jpg/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2026/2026 [05:45<00:00,  5.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pngs saved to /kaggle/working/pngs/\n",
      "Elapsed time: 9287.10s\n",
      "chunk 21 of 27 chunks\n",
      "Converting dicom to jpg...\n",
      "jpg files saved to /tmp/jpg/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2027/2027 [05:37<00:00,  6.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pngs saved to /kaggle/working/pngs/\n",
      "Elapsed time: 9741.65s\n",
      "chunk 22 of 27 chunks\n",
      "Converting dicom to jpg...\n",
      "jpg files saved to /tmp/jpg/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2026/2026 [05:46<00:00,  5.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pngs saved to /kaggle/working/pngs/\n",
      "Elapsed time: 10206.46s\n",
      "chunk 23 of 27 chunks\n",
      "Converting dicom to jpg...\n",
      "jpg files saved to /tmp/jpg/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2026/2026 [05:56<00:00,  5.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pngs saved to /kaggle/working/pngs/\n",
      "Elapsed time: 10682.46s\n",
      "chunk 24 of 27 chunks\n",
      "Converting dicom to jpg...\n",
      "jpg files saved to /tmp/jpg/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2026/2026 [06:00<00:00,  5.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pngs saved to /kaggle/working/pngs/\n",
      "Elapsed time: 11167.17s\n",
      "chunk 25 of 27 chunks\n",
      "Converting dicom to jpg...\n",
      "jpg files saved to /tmp/jpg/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2026/2026 [05:46<00:00,  5.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pngs saved to /kaggle/working/pngs/\n",
      "Elapsed time: 11638.95s\n",
      "chunk 26 of 27 chunks\n",
      "Converting dicom to jpg...\n",
      "jpg files saved to /tmp/jpg/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2026/2026 [05:59<00:00,  5.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pngs saved to /kaggle/working/pngs/\n",
      "Elapsed time: 12121.81s\n",
      "chunk 27 of 27 chunks\n",
      "Converting dicom to jpg...\n",
      "jpg files saved to /tmp/jpg/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2027/2027 [05:31<00:00,  6.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pngs saved to /kaggle/working/pngs/\n",
      "Elapsed time: 12572.86s\n",
      "DALI Raw image load complete\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "for i_chunk, chunk in enumerate(CHUNKS):\n",
    "    print(f'chunk {i_chunk+1} of {len(CHUNKS)} chunks')\n",
    "    os.makedirs(JPG_FOLDER, exist_ok=True)\n",
    "\n",
    "    print(f\"Converting dicom to jpg...\")\n",
    "    _ = Parallel(n_jobs=2)(\n",
    "        delayed(convert_dicom_to_jpg)(f'{DATA_FOLDER}/{img}', save_folder=JPG_FOLDER)\n",
    "        for img in train_df[\"fns\"].tolist()[chunk[0]: chunk[1]]\n",
    "    )\n",
    "    print(f\"jpg files saved to {JPG_FOLDER}\")\n",
    "    \n",
    "    jpgfiles = glob.glob(JPG_FOLDER + \"*.jpg\")\n",
    "\n",
    "\n",
    "    pipe = jpg_decode_pipeline(jpgfiles, batch_size=1, num_threads=2, device_id=0)\n",
    "    pipe.build()\n",
    "\n",
    "    for i, f in enumerate(tqdm(jpgfiles)):\n",
    "        \n",
    "        patient, dicom_id = f.split('/')[-1][:-4].split('_')\n",
    "        dicom = pydicom.dcmread(DATA_FOLDER + f\"/{patient}/{dicom_id}.dcm\")\n",
    "        try:\n",
    "            out = pipe.run()\n",
    "            # Dali -> Torch\n",
    "            img = out[0][0]\n",
    "            img_torch = torch.empty(img.shape(), dtype=torch.int16, device=\"cuda\")\n",
    "            feed_ndarray(img, img_torch, cuda_stream=torch.cuda.current_stream(device=0))\n",
    "            img = img_torch.float()\n",
    "\n",
    "            #apply dicom preprocessing\n",
    "            img = process_dicom(img, dicom)\n",
    "\n",
    "            #resize the torch image\n",
    "            img = F.interpolate(img.view(1, 1, img.size(0), img.size(1)), (SAVE_SIZE, SAVE_SIZE), mode=\"bilinear\")[0, 0]\n",
    "\n",
    "            img = (img * 255).clip(0,255).to(torch.uint8).cpu().numpy()\n",
    "            out_file_name = SAVE_FOLDER + f\"{patient}_{dicom_id}.png\"\n",
    "            saved = cv2.imwrite(out_file_name, img)\n",
    "            if not saved:\n",
    "                print(f\"Could not save {out_file_name}\")\n",
    "    \n",
    "        except Exception as e:\n",
    "            print(i, e)\n",
    "            pipe = jpg_decode_pipeline(jpgfiles[i+1:], batch_size=1, num_threads=2, device_id=0)\n",
    "            pipe.build()\n",
    "            continue\n",
    "\n",
    "    print(f\"pngs saved to {SAVE_FOLDER}\")\n",
    "    print(f\"Elapsed time: {time.time()-t0:.2f}s\")\n",
    "    \n",
    "    shutil.rmtree(JPG_FOLDER)\n",
    "    \n",
    "#     break\n",
    "    \n",
    "print(f'DALI Raw image load complete')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 12695.521231,
   "end_time": "2023-02-13T21:29:50.984419",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-02-13T17:58:15.463188",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
